‚úàÔ∏è DST Airlines - Data Pipeline
Projet de pipeline de donn√©es automatis√© pour le suivi des vols et des infrastructures a√©roportuaires. Ce projet utilise une architecture Medallion pour garantir la qualit√© et l'historisation des donn√©es.

üèóÔ∏è Architecture des Donn√©es
Le projet repose sur une base PostgreSQL distante structur√©e en deux sch√©mas principaux :

Staging (Bronze) : R√©ception des donn√©es brutes de l'API AirLabs. Les tables sont √©cras√©es √† chaque rafra√Æchissement (Replace).

Acquisition (Silver) : Donn√©es nettoy√©es, d√©doublonn√©es et enrichies.

Les a√©roports sont historis√©s et enrichis avec des donn√©es g√©ographiques via OpenStreetMap.

Les vols sont g√©r√©s via une logique d'Upsert (Update or Insert) pour conserver l'historique sans doublons.

üõ†Ô∏è Installation et Configuration
1. Pr√©requis
Python 3.10+

Un environnement virtuel actif (env)

La biblioth√®que python-dotenv pour la gestion des secrets.

2. Installation des d√©pendances
Bash
pip install -r requirements.txt
3. Configuration de l'environnement
Cr√©ez un fichier .env √† la racine du projet (ce fichier est ignor√© par Git). Utilisez le mod√®le suivant :

Extrait de code
# API Key AirLabs
AIRLABS_API_KEY=votre_cle_api

# Base de Donn√©es PostgreSQL (Serveur Distant)
DB_USER=exploitation
DB_PASSWORD=votre_mot_de_passe
DB_HOST=XX.XX.XX.XX  # Demander l'IP √† l'administrateur
DB_PORT=5432
DB_NAME=data_hub
üöÄ Utilisation du Pipeline
Ex√©cutez les scripts dans l'ordre suivant pour mettre √† jour la base :

Ingestion : python 1_ingestion/ingestion_airlabs.py

Nettoyage Silver : python 2_silver_processing/silver_flights_clean.py

Enrichissement G√©o : python 2_silver_processing/silver_airports_geo.py

üìà √âvolutions √† venir (Roadmap)
[ ] Migration de la couche Bronze vers MongoDB (Docker local).

[ ] Mise en place de dbt pour les transformations SQL.

[ ] Cr√©ation de la couche Gold pour les indicateurs de performance (KPIs).