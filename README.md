# ‚úàÔ∏è DST Airlines - Data Pipeline (ELT Edition)

Projet de pipeline de donn√©es automatis√© pour le suivi des vols. Le projet a √©t√© migr√© d'une structure de scripts isol√©s vers une architecture **ELT (Extract-Load-Transform)** pilot√©e par **Airflow** et **dbt**.

## üèóÔ∏è Architecture des Donn√©es

Le projet utilise l'architecture **Medallion** sur PostgreSQL (Supabase) :

* **Bronze (Schema: `bronze`)** : Ingestion des donn√©es brutes au format JSON depuis l'API **Air France-KLM**.
* **Silver (Schema: `silver`)** : 
    * `s_flights` : Nettoyage, typage et structuration des donn√©es de vols.
    * `s_airports` : Dimension de r√©f√©rence extraite dynamiquement des donn√©es de vols (Codes IATA, noms, villes et coordonn√©es GPS).
* **Gold (Schema: `gold`)** : Couche de pr√©sentation pour le reporting et les KPIs.



## üõ†Ô∏è Stack Technique

* **Source** : API Air France-KLM (Open Data).
* **Orchestration** : Airflow (Scripts d'ingestion Bronze).
* **Transformation** : dbt (Data Build Tool) pour le modeling SQL.
* **Stockage** : PostgreSQL (Supabase).

## üöÄ Installation et Configuration

### 1. Pr√©requis
* Python 3.10+
* Un environnement virtuel actif (`venv`)
* Acc√®s SSH configur√© pour GitHub

### 2. Configuration de l'environnement
Cr√©ez un fichier `.env` √† la racine du projet :
```env
# API Key Air France-KLM
AF_API_KEY=votre_cle_api

# Base de Donn√©es PostgreSQL
DB_USER=postgres
DB_PASSWORD=votre_mot_de_passe
DB_HOST=votre_host_supabase
DB_PORT=5432
DB_NAME=postgres
DB_SCHEMA=silver